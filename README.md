# 상표 검색 API

본 프로젝트는 상표 데이터베이스를 검색하고 필터링하기 위한 RESTful API 서비스입니다. PostgreSQL의 고급 검색 기능을 활용하여 상표명, 출원번호 등으로 효율적인 검색을 지원합니다.

## API 사용법 및 실행 방법

### 환경 설정 및 실행

1. 저장소 클론:

   ```bash
   git clone <repository-url>
   cd markcloud
   ```

2. 도커 컴포즈를 사용한 실행:

   ```bash
   docker-compose up -d
   ```

   - 기본적으로 PostgreSQL 데이터베이스가 `5432` 포트에서 실행됩니다.
   - pgAdmin은 `5050` 포트에서 `--profile admin` 옵션을 사용할 때만 실행됩니다.

3. 로컬 개발 환경 설정:

   ```bash
   # 가상환경 생성 및 활성화
   python -m venv venv
   source venv/bin/activate  # Windows: venv\Scripts\activate

   # 의존성 설치
   pip install -r requirements.txt

   # 애플리케이션 실행
   uvicorn app.main:app --reload
   ```

### API 엔드포인트

기본 URL: `http://localhost:8000/api/v1`

#### 상표 검색 API

- **GET** `/api/v1/trademarks`
- **쿼리 파라미터**:
  - `query`: 검색어 (상표명, 출원번호 등)
  - `status`: 상표 등록 상태 필터
  - `product_code`: 상품 분류 코드 필터
  - `from_date`, `to_date`: 날짜 범위 필터
  - `offset`, `limit`: 페이징 처리

#### 상표 상세 정보 API

- **GET** `/api/v1/trademarks/{trademark_id}`

#### 메타데이터 API

- **GET** `/api/v1/trademarks/meta/statuses` - 등록 상태 목록
- **GET** `/api/v1/trademarks/meta/product-codes` - 상품 분류 코드 목록

### 스웨거 문서

API 문서는 다음 URL에서 확인할 수 있습니다:

- Swagger UI: `http://localhost:8000/docs`
- ReDoc: `http://localhost:8000/redoc`

## 구현된 기능 설명

### 1. 검색 기능

- **키워드 검색**: 상표명(한글/영문), 출원번호 등으로 검색
- **유사도 기반 검색**: PostgreSQL의 pg_trgm 확장을 활용한 트리그램 유사도 검색
- **한글 초성 검색**: 'ㅅㅂㅅ'로 '스타벅스' 검색 등 초성만으로 검색 가능
- **전문 검색**: tsvector/tsquery를 활용한 효율적인 텍스트 검색

### 2. 필터링 기능

- **등록 상태 필터**: 등록, 출원, 거절, 실효 등 상태별 필터링
- **상품 코드 필터**: 상품 주 분류 코드별 필터링
- **날짜 범위 필터**: 출원일, 등록일, 공고일 등 날짜 범위 필터링
- **페이징 처리**: 대량의 결과를 효율적으로 처리하기 위한 페이징

### 3. 메타데이터 API

- **등록 상태 목록**: 시스템에 등록된 모든 상태값 조회
- **상품 분류 코드**: 시스템에 등록된 모든 상품 분류 코드 조회

## 기술적 의사결정

### 1. PostgreSQL + GIN + pg_trgm 선택 이유

PostgreSQL을 데이터베이스로 선택한 주요 이유는 다음과 같습니다:

- **트리그램 유사도 검색**: pg_trgm 확장을 통해 효율적인 유사도 검색 지원
- **GIN 인덱스 활용**: 전문 검색과 배열 필드 검색을 위한 최적화된 인덱스
- **JSONB 지원**: 리스트 형태의 필드를 효율적으로 저장 및 검색
- **오픈소스 및 확장성**: 무료로 사용 가능하며 다양한 확장 기능 제공

### 2. 계층화된 아키텍처

코드의 가독성, 유지보수성, 확장성을 높이기 위해 계층화된 아키텍처를 적용했습니다:

- **Repository 패턴**: 데이터 액세스 로직을 캡슐화
- **Service 레이어**: 비즈니스 로직 담당
- **Router 레이어**: API 엔드포인트 정의
- **Schema 레이어**: 요청/응답 데이터 검증 및 변환

### 3. 하이브리드 검색 방식

대량 데이터와 검색 품질을 모두 고려한 하이브리드 검색 방식을 채택했습니다:

- **DB 레벨 1차 필터링**: 인덱스를 활용한 고성능 초기 필터링
- **애플리케이션 레벨 후처리**: 결과가 적을 경우 Python 코드로 추가 정렬 및 필터링
- **유틸리티 함수 활용**: 검색어 분석 및 처리를 위한 경량 유틸리티 함수

## 문제 해결 과정에서 고민했던 점

### 1. 한글 초성 검색 구현

한글 초성만으로 검색하는 기능을 구현하기 위해 여러 접근법을 고려했습니다:

- **Python 유틸리티 함수**: 초성 추출 및 매칭 로직을 구현
- **PostgreSQL 함수**: 데이터베이스 레벨에서 초성 추출 함수 구현
- **하이브리드 접근법**: Python으로 초성 여부 판별 + DB 함수로 매칭

결과적으로 하이브리드 방식이 성능과 확장성 측면에서 가장 효율적이었습니다. Python으로 초성 여부를 판별하고, DB 함수로 실제 매칭을 수행하는 방식을 채택했습니다.

### 2. 퍼지 검색과 정확도 균형

검색의 정확도와 유연성 사이의 균형을 맞추기 위해 다양한 접근법을 실험했습니다:

- **트리그램 유사도**: 오타나 부분 일치에도 검색 결과를 제공
- **전문 검색**: 키워드 기반의 정확한 검색 지원
- **유사도 임계값**: 적절한 유사도 임계값(0.3)을 설정하여 정확도 조정
- **유사도 기반 정렬**: 가장 관련성 높은 결과가 상위에 노출되도록 구현

### 3. 대용량 데이터 처리 방안

10만 건 이상의 데이터를 효율적으로 처리하기 위한 전략을 수립했습니다:

- **인덱스 최적화**: GIN 인덱스, B-tree 인덱스 등 적절한 인덱스 설계
- **페이징 처리**: 대량의 결과를 관리 가능한 크기로 분할
- **배치 처리**: 데이터 로딩 시 배치 처리로 메모리 사용량 최적화
- **쿼리 최적화**: 필터링을 먼저 적용하여 검색 범위 축소

### 4. 배열 필드 처리

상품 코드, 비엔나 코드 등 배열 형태의 필드를 효율적으로 처리하기 위한 방법을 고민했습니다:

- **PostgreSQL 배열 타입**: 배열 데이터를 네이티브하게 저장
- **GIN 인덱스**: 배열 요소 검색을 위한 인덱스 최적화
- **any() 연산자**: 배열 내 요소 검색을 위한 효율적인 연산자 활용
- **unnest() 함수**: 메타데이터 조회 시 배열을 행으로 펼쳐서 처리

## 개선 계획

### 1. 성능 최적화

- **캐싱 레이어**: Redis를 활용한 자주 사용되는 검색 결과 캐싱
- **파티셔닝**: pg_partman을 활용한 테이블 파티셔닝으로 대용량 데이터 처리 개선
- **쿼리 튜닝**: EXPLAIN ANALYZE를 활용한 쿼리 성능 분석 및 최적화

### 2. 검색 품질 개선

- **형태소 분석**: 한국어 형태소 분석을 통한 검색 정확도 향상
- **오타 교정**: 자동 오타 교정 및 추천 검색어 기능 추가
- **유사도 알고리즘 개선**: 다양한 유사도 알고리즘 실험 및 비교

### 3. 확장성 개선

- **Elasticsearch 연동**: 더 고급 검색 기능이 필요할 경우 Elasticsearch 도입 검토
- **비동기 처리**: 대용량 데이터 처리를 위한 비동기 작업 구현

## 기술 스택

- **Backend**: FastAPI, Pydantic, SQLAlchemy
- **Database**: PostgreSQL, pg_trgm, GIN 인덱스
- **Containerization**: Docker, Docker Compose
- **Testing**: Pytest
- **기타**: Python-dotenv, Logging
